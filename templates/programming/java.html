<h1 align="center" > Java Notes </h1>	

<h5 align="left"  > published on 10 Oct. 2010 </h5>

<hr>

</br>


<pre>

<a name="JavaForkandJoinusingForkJoinPool" href="#/javaBlog#JavaForkandJoinusingForkJoinPool" >Java Fork and Join using ForkJoinPool</a>

				
The ForkJoinPool was added to Java in Java 7. The ForkJoinPool is similar to the Java ExecutorService but with one difference. The ForkJoinPool makes it easy for tasks to split their work up into smaller tasks which are then submitted to the ForkJoinPool too. Tasks can keep splitting their work into smaller subtasks for as long as it makes to split up the task. It may sound a bit abstract, so in this fork and join tutorial I will explain how the ForkJoinPool works, and how splitting tasks up work. 

<b>Fork and Join Explained</b>

Before we look at the ForkJoinPool I want to explain how the fork and join principle works in general.

The fork and join principle consists of two steps which are performed recursively. These two steps are the fork step and the join step.

<b>Fork</b>

A task that uses the fork and join principle can fork (split) itself into smaller subtasks which can be executed concurrently. This is illustrated in the diagram below: 

<img src="/templates/programming/java/java-fork-and-join-1.png" />

By splitting itself up into subtasks, each subtask can be executed in parallel by different CPUs, or different threads on the same CPU.

A task only splits itself up into subtasks if the work the task was given is large enough for this to make sense. There is an overhead to splitting up a task into subtasks, so for small amounts of work this overhead may be greater than the speedup achieved by executing subtasks concurrently.

The limit for when it makes sense to fork a task into subtasks is also called a threshold. It is up to each task to decide on a sensible threshold. It depends very much on the kind of work being done.


<b>Join</b>

When a task has split itself up into subtasks, the task waits until the subtasks have finished executing.

Once the subtasks have finished executing, the task may join (merge) all the results into one result. This is illustrated in the diagram below: 

<img src="/templates/programming/java/java-fork-and-join-2.png" />

Of course, not all types of tasks may return a result. If the tasks do not return a result then a task just waits for its subtasks to complete. No result merging takes place then.

<b>The ForkJoinPool</b>

The ForkJoinPool is a special thread pool which is designed to work well with fork-and-join task splitting. The ForkJoinPool located in the java.util.concurrent package, so the full class name is java.util.concurrent.ForkJoinPool.

<b>Creating a ForkJoinPool</b>

You create a ForkJoinPool using its constructor. As a parameter to the ForkJoinPool constructor you pass the indicated level of parallelism you desire. The parallelism level indicates how many threads or CPUs you want to work concurrently on on tasks passed to the ForkJoinPool. Here is a ForkJoinPool creation example: 
    
    ForkJoinPool forkJoinPool = new ForkJoinPool(4);
    
This example creates a ForkJoinPool with a parallelism level of 4. 

<b>Submitting Tasks to the ForkJoinPool</b>

You submit tasks to a ForkJoinPool similarly to how you submit tasks to an ExecutorService. You can submit two types of tasks. A task that does not return any result (an "action"), and a task which does return a result (a "task"). These two types of tasks are represented by the RecursiveAction and RecursiveTask classes. How to use both of these tasks and how to submit them will be covered in the following sections. 

<b>RecursiveAction</b>

A RecursiveAction is a task which does not return any value. It just does some work, e.g. writing data to disk, and then exits.

A RecursiveAction may still need to break up its work into smaller chunks which can be executed by independent threads or CPUs.

You implement a RecursiveAction by subclassing it. Here is a RecursiveAction example: 

<div class="code_container">
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.RecursiveAction;

public class MyRecursiveAction extends RecursiveAction {

    private long workLoad = 0;

    public MyRecursiveAction(long workLoad) {
        this.workLoad = workLoad;
    }

    @Override
    protected void compute() {

        //if work is above threshold, break tasks up into smaller tasks
        if(this.workLoad > 16) {
            System.out.println("Splitting workLoad : " + this.workLoad);

            List<MyRecursiveAction> subtasks =
                new ArrayList<MyRecursiveAction>();

            subtasks.addAll(createSubtasks());

            for(RecursiveAction subtask : subtasks){
                subtask.fork();
            }

        } else {
            System.out.println("Doing workLoad myself: " + this.workLoad);
        }
    }

    private List<MyRecursiveAction> createSubtasks() {
        List<MyRecursiveAction> subtasks =
            new ArrayList<MyRecursiveAction>();

        MyRecursiveAction subtask1 = new MyRecursiveAction(this.workLoad / 2);
        MyRecursiveAction subtask2 = new MyRecursiveAction(this.workLoad / 2);

        subtasks.add(subtask1);
        subtasks.add(subtask2);

        return subtasks;
    }

}


import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.RecursiveAction;

public class MyRecursiveAction extends RecursiveAction {

    private long workLoad = 0;

    public MyRecursiveAction(long workLoad) {
        this.workLoad = workLoad;
    }

    @Override
    protected void compute() {

        //if work is above threshold, break tasks up into smaller tasks
        if(this.workLoad > 16) {
            System.out.println("Splitting workLoad : " + this.workLoad);

            List<MyRecursiveAction> subtasks =
                new ArrayList<MyRecursiveAction>();

            subtasks.addAll(createSubtasks());

            for(RecursiveAction subtask : subtasks){
                subtask.fork();
            }

        } else {
            System.out.println("Doing workLoad myself: " + this.workLoad);
        }
    }

    private List<MyRecursiveAction> createSubtasks() {
        List<MyRecursiveAction> subtasks =
            new ArrayList<MyRecursiveAction>();

        MyRecursiveAction subtask1 = new MyRecursiveAction(this.workLoad / 2);
        MyRecursiveAction subtask2 = new MyRecursiveAction(this.workLoad / 2);

        subtasks.add(subtask1);
        subtasks.add(subtask2);

        return subtasks;
    }

}

</div>



This example is very simplified. The MyRecursiveAction simply takes a fictive workLoad as parameter to its constructor. If the workLoad is above a certain threshold, the work is split into subtasks which are also scheduled for execution (via the .fork() method of the subtasks. If the workLoad is below a certain threshold then the work is carried out by the MyRecursiveAction itself.

You can schedule a MyRecursiveAction for execution like this: 

    MyRecursiveAction myRecursiveAction = new MyRecursiveAction(24);

    forkJoinPool.invoke(myRecursiveAction);
    

<b>RecursiveTask</b>

A RecursiveTask is a task that returns a result. It may split its work up into smaller tasks, and merge the result of these smaller tasks into a collective result. The splitting and merging may take place on several levels. Here is a RecursiveTask example: 

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.RecursiveTask;
    
    
public class MyRecursiveTask extends RecursiveTask<Long> {

    private long workLoad = 0;

    public MyRecursiveTask(long workLoad) {
        this.workLoad = workLoad;
    }

    protected Long compute() {

        //if work is above threshold, break tasks up into smaller tasks
        if(this.workLoad > 16) {
            System.out.println("Splitting workLoad : " + this.workLoad);

            List<MyRecursiveTask> subtasks =
                new ArrayList<MyRecursiveTask>();
            subtasks.addAll(createSubtasks());

            for(MyRecursiveTask subtask : subtasks){
                subtask.fork();
            }

            long result = 0;
            for(MyRecursiveTask subtask : subtasks) {
                result += subtask.join();
            }
            return result;

        } else {
            System.out.println("Doing workLoad myself: " + this.workLoad);
            return workLoad * 3;
        }
    }

    private List<MyRecursiveTask> createSubtasks() {
        List<MyRecursiveTask> subtasks =
        new ArrayList<MyRecursiveTask>();

        MyRecursiveTask subtask1 = new MyRecursiveTask(this.workLoad / 2);
        MyRecursiveTask subtask2 = new MyRecursiveTask(this.workLoad / 2);

        subtasks.add(subtask1);
        subtasks.add(subtask2);

        return subtasks;
    }
}

This example is similar to the RecursiveAction example except it returns a result. The class MyRecursiveTask extends RecursiveTask<Long> which means that the result returned from the task is a Long .

The MyRecursiveTask example also breaks the work down into subtasks, and schedules these subtasks for execution using their fork() method.

Additionally, this example then receives the result returned by each subtask by calling the join() method of each subtask. The subtask results are merged into a bigger result which is then returned. This kind of joining / mergining of subtask results may occur recursively for several levels of recursion.

You can schedule a RecursiveTask like this: 

    MyRecursiveTask myRecursiveTask = new MyRecursiveTask(128);

    long mergedResult = forkJoinPool.invoke(myRecursiveTask);

    System.out.println("mergedResult = " + mergedResult); 
    
Notice how you get the final result out from the ForkJoinPool.invoke() method call.

<b>ForkJoinPool Critique</b>

It seems not everyone is equally happy with the new ForkJoinPool in Java 7. While searching for experiences with, and opinions about, the ForkJoinPool, there are some critique: 

    <a href='http://coopsoft.com/ar/CalamityArticle.html'> A Java Fork-Join Calamity </a>

It is well worth a read before you plan to use the ForkJoinPool in your own projects. 

<hr style="border-top: 1px;" />

</pre>



<pre> 

<a name="Java8NewFeatures" href="#/javaBlog#Java8NewFeatures" >Java 8 New Features</a>


New Features
There are dozens of features added to Java 8, the most significant ones are mentioned below −

    Lambda expression − Adds functional processing capability to Java.
    Method references − Referencing functions by their names instead of invoking them directly. Using functions as parameter.
    Default method − Interface to have default method implementation.
    New tools − New compiler tools and utilities are added like ‘jdeps’ to figure out dependencies.
    Stream API − New stream API to facilitate pipeline processing.
    Date Time API − Improved date time API.
    Optional − Emphasis on best practices to handle null values properly.
    Nashorn, JavaScript Engine − A Java-based engine to execute JavaScript code.

Along with these new featuers, lots of feature enhancements are done under-the-hood, at both compiler and JVM level.

- sample for java 8

import java.util.Collections;
import java.util.List;
import java.util.ArrayList;
import java.util.Comparator;

public class Java8Tester {
   public static void main(String args[]){
   
      List<String> names1 = new ArrayList<String>();
      names1.add("Mahesh ");
      names1.add("Suresh ");
      names1.add("Ramesh ");
      names1.add("Naresh ");
      names1.add("Kalpesh ");
  
      List<String> names2 = new ArrayList<String>();
      names2.add("Mahesh ");
      names2.add("Suresh ");
      names2.add("Ramesh ");
      names2.add("Naresh ");
      names2.add("Kalpesh ");
  
      Java8Tester tester = new Java8Tester();
      System.out.println("Sort using Java 7 syntax: ");
  
      tester.sortUsingJava7(names1);
      System.out.println(names1);
      System.out.println("Sort using Java 8 syntax: ");
  
      tester.sortUsingJava8(names2);
      System.out.println(names2);
   }
   
   //sort using java 7
   private void sortUsingJava7(List<String> names){   
      Collections.sort(names, new Comparator<String>() {
         @Override
         public int compare(String s1, String s2) {
            return s1.compareTo(s2);
         }
      });
   }
   
   //sort using java 8
   private void sortUsingJava8(List<String> names){
      Collections.sort(names, (s1, s2) -> s1.compareTo(s2));
   }
}




Lambda expression facilitates functional programming, and simplifies the development a lot.


A lambda expression is characterized by the following syntax −

parameter -> expression body

Following are the important characteristics of a lambda expression −

    Optional type declaration − No need to declare the type of a parameter. The compiler can inference the same from the value of the parameter.
    Optional parenthesis around parameter − No need to declare a single parameter in parenthesis. For multiple parameters, parentheses are required.
    Optional curly braces − No need to use curly braces in expression body if the body contains a single statement.

Optional return keyword − The compiler automatically returns the value if the body has a single expression to return the value. Curly braces are required to indicate that expression returns a value.



public class Java8Tester {
   public static void main(String args[]){
      Java8Tester tester = new Java8Tester();
  
      //with type declaration
      MathOperation addition = (int a, int b) -> a + b;
  
      //with out type declaration
      MathOperation subtraction = (a, b) -> a - b;
  
      //with return statement along with curly braces
      MathOperation multiplication = (int a, int b) -> { return a * b; };
  
      //without return statement and without curly braces
      MathOperation division = (int a, int b) -> a / b;
  
      System.out.println("10 + 5 = " + tester.operate(10, 5, addition));
      System.out.println("10 - 5 = " + tester.operate(10, 5, subtraction));
      System.out.println("10 x 5 = " + tester.operate(10, 5, multiplication));
      System.out.println("10 / 5 = " + tester.operate(10, 5, division));
  
      //with parenthesis
      GreetingService greetService1 = message ->
      System.out.println("Hello " + message);
  
      //without parenthesis
      GreetingService greetService2 = (message) ->
      System.out.println("Hello " + message);
  
      greetService1.sayMessage("Mahesh");
      greetService2.sayMessage("Suresh");
   }
 
   interface MathOperation {
      int operation(int a, int b);
   }
 
   interface GreetingService {
      void sayMessage(String message);
   }
 
   private int operate(int a, int b, MathOperation mathOperation){
      return mathOperation.operation(a, b);
   }
}


Lambda expressions are used primarily to define inline implementation of a functional interface, i.e., an interface with a single method only. In the above example, we've used various types of lambda expressions to define the operation method of MathOperation interface. Then we have defined the implementation of sayMessage of GreetingService.

Lambda expression eliminates the need of anonymous class and gives a very simple yet powerful functional programming capability to Java.

Method references help to point to methods by their names. A method reference is described using :: (double colon) symbol. A method reference can be used to point the following types of methods −

    Static methods
    Instance methods
    Constructors using new operator (TreeSet::new)

	

Method Reference Example

Let's look into an example of method referencing to get a more clear picture. Write the following program in an code editor and match the results.

import java.util.List;
import java.util.ArrayList;

public class Java8Tester {
   public static void main(String args[]){
      List names = new ArrayList();
  
      names.add("Mahesh");
      names.add("Suresh");
      names.add("Ramesh");
      names.add("Naresh");
      names.add("Kalpesh");
  
      names.forEach(System.out::println);
   }
}	

</pre>
<hr style="border-top: 1px;" />
<pre>

Vector or ArrayList -- which is better?

Sometimes Vector is better; sometimes ArrayList is better; sometimes you don't want to use either. I hope you weren't looking for an easy answer because the answer depends upon what you are doing. There are four factors to consider:

API
Synchronization
Data growth
Usage patterns
Let's explore each in turn.

API

In The Java Programming Language (Addison-Wesley, June 2000) Ken Arnold, James Gosling, and David Holmes describe the Vector as an analog to the ArrayList. So, from an API perspective, the two classes are very similar. However, there are still some major differences between the two classes.

Synchronization

Vectors are synchronized. Any method that touches the Vector's contents is thread safe. ArrayList, on the other hand, is unsynchronized, making them, therefore, not thread safe. With that difference in mind, using synchronization will incur a performance hit. So if you don't need a thread-safe collection, use the ArrayList. Why pay the price of synchronization unnecessarily?

Data growth

Internally, both the ArrayList and Vector hold onto their contents using an Array. You need to keep this fact in mind while using either in your programs. When you insert an element into an ArrayList or a Vector, the object will need to expand its internal array if it runs out of room. A Vector defaults to doubling the size of its array, while the ArrayList increases its array size by 50 percent. Depending on how you use these classes, you could end up taking a large performance hit while adding new elements. It's always best to set the object's initial capacity to the largest capacity that your program will need. By carefully setting the capacity, you can avoid paying the penalty needed to resize the internal array later. If you don't know how much data you'll have, but you do know the rate at which it grows, Vector does possess a slight advantage since you can set the increment value.

Usage patterns

Both the ArrayList and Vector are good for retrieving elements from a specific position in the container or for adding and removing elements from the end of the container. All of these operations can be performed in constant time -- O(1). However, adding and removing elements from any other position proves more expensive -- linear to be exact: O(n-i), where n is the number of elements and i is the index of the element added or removed. These operations are more expensive because you have to shift all elements at index i and higher over by one element. So what does this all mean?

It means that if you want to index elements or add and remove elements at the end of the array, use either a Vector or an ArrayList. If you want to do anything else to the contents, go find yourself another container class. For example, the LinkedList can add or remove an element at any position in constant time -- O(1). However, indexing an element is a bit slower -- O(i) where i is the index of the element. Traversing an ArrayList is also easier since you can simply use an index instead of having to create an iterator. The LinkedList also creates an internal object for each element inserted. So you have to be aware of the extra garbage being created.

Finally, in "PRAXIS 41" from Practical Java (Addison-Wesley, Feb. 2000) Peter Haggar suggests that you use a plain old array in place of either Vector or ArrayList -- especially for performance-critical code. By using an array you can avoid synchronization, extra method calls, and suboptimal resizing. You just pay the cost of extra development time.

</pre>
<hr style="border-top: 1px;" />
<pre>

What to do when your eclipse maven project shows errors in eclipse and compiled successfully !!!!

When your Maven eclipse project shows errors in eclipse editor and it can compile with eclipse or console at that time there must be project configuration issue with eclipse happened, when you open close multiple projects its happens sometime with eclipse.

do

mvn eclipse : eclipse

from your command line by closing eclipse and open eclipse again and refresh projects, error will go away!

</pre>
<hr style="border-top: 1px;" />

<pre>

<a name="Java7sNewFeatures" href="#/javaBlog#Java7sNewFeatures" >Java 7's new Features</a>


There are a number of features in Java 7 that will please developers. Things such as strings in switch statements, multi-catch exception handling, try-with-resource statements, the new File System API, extensions of the JVM, support for dynamically-typed languages, the fork and join framework for task parallelism, and a few others will certainly be embraced by the community.
Below I outline the features and provide examples where appropriate. A zip file containing code snippets used in this post can be downloaded here.
Language enhancements
Java 7 includes a few new language features via Project Coin. These features are quite handy for a developer.
Diamond Operator
You may have noted on many occasions your IDE complaining of types when working with Generics. For example, if we have to declare a map of trades using Generics, we write the code as follows:

Map<String, List<Trade>> trades = new TreeMap<String, List<Trade>> ();

The not-so-nice thing about this declaration is that we must declare the types on both the sides, although the right-hand side seems a bit redundant. Can the compiler infer the types by looking at the left-hand-side declaration? Not unless you’re using Java 7. In 7, it’s written like this:

Map<String, List<Trade>> trades = new TreeMap <> ();

How cool is that? You don’t have to type the whole list of types for the instantiation. Instead you use the <> symbol, which is called diamond operator. Note that while not declaring the diamond operator is legal, as trades = new TreeMap (), it will make the compiler generate a couple of type-safety warnings.
Using strings in switch statements
Switch statements work either with primitive types or enumerated types. Java 7 introduced another type that we can use in Switch statements: the String type.
Say we have a requirement to process a Trade based on its status. Until now we used to do this by using if-else statements.

private void processTrade(Trade t) {

            String status = t.getStatus();

            if (status.equalsIgnoreCase(NEW)) {

                  newTrade(t);

            } else if (status.equalsIgnoreCase(EXECUTE)) {

                  executeTrade(t);

            } else if (status.equalsIgnoreCase(PENDING)) {

                  pendingTrade(t);

            }

}

This method of working on strings is crude. In Java 7, we can improve the program by utilizing the enhanced Switch statement, which takes a String type as an argument.

 public void processTrade(Trade t) {

            String status = t.getStatus();



            switch (status) {

            case NEW:

                  newTrade(t);

                  break;

            case EXECUTE:

                  executeTrade(t);

                  break;

            case PENDING:

                  pendingTrade(t);

                  break;



            default:

                  break;

            }

      }
      

In the above program, the status field is always compared against the case label by using theString.equals() method.
Automatic resource management
Resources such as Connections, Files, Input/OutStreams, etc. should be closed manually by the developer by writing bog-standard code. Usually we use a try-finally block to close the respective resources. See the current practice of creating a resource, using it and finally closing it:

public void oldTry() {

            try {

                  fos = new FileOutputStream("movies.txt");

                  dos = new DataOutputStream(fos);

                  dos.writeUTF("Java 7 Block Buster");

            } catch (IOException e) {

                  e.printStackTrace();

            } finally {

                  try {

                        fos.close();

                        dos.close();

                  } catch (IOException e) {

                        // log the exception

                  }

            }

      }

However, Java 7 has introduced another cool feature to manage the resources automatically. It is simple in operation, too. All we have to do is declare the resources in the try as follows:

try(resources_to_be_cleant){

   // your code

}

The above method with the old try can finally can be re-written using this new feature as shown below:

      public void newTry() {



            try (FileOutputStream fos = new FileOutputStream("movies.txt");

                        DataOutputStream dos = new DataOutputStream(fos)) {

                  dos.writeUTF("Java 7 Block Buster");

            } catch (IOException e) {

                  // log the exception

            }

      }

The above code also represents another aspect of this feature: working with multiple resources. The FileOutputStream and DataOutputStream resources are enclosed in the try statement one after the other, each one separated by a semicolon (;) separator. We do not have to nullify or close the streams manually, as they are closed automatically once the control exists the try block.
Behind the scenes, the resources that should be auto closed must implementjava.lang.AutoCloseable interface.
Any resource that implements AutoCloseble interface can be a candidate for automatic resource management. The AutoCloseable is the parent of java.io.Closeable interface and has just one method close() that would be called by the JVM when the control comes out of the try block.
Numeric literals with underscores
Numerical literals are definitely eye strainers. I am sure you would start counting the zeroes like me if you’ve been given a number with, say, ten zeros. It’s quite error prone and cumbersome to identify a literal if it’s a million or a billion unless you count the places from right to left. Not anymore. Java 7 introduced underscores in identifying the places. For example, you can declare 1000 as shown below:

int thousand =  1_000;

or 1000000 (one million) as follows

int million  =  1_000_000

Note that binary literals are also introduced in this release too — for example “0b1″ — so developers don’t have to convert them to hexadecimals any more.
Improved exception handling
There are a couple of improvements in the exception handling area. Java 7 introduced multi-catch functionality to catch multiple exception types using a single catch block.
Let’s say you have a method that throws three exceptions. In the current state, you would deal them individually as shown in below:

   public void oldMultiCatch() {

            try {

                  methodThatThrowsThreeExceptions();

            } catch (ExceptionOne e) {

                  // log and deal with ExceptionOne

            } catch (ExceptionTwo e) {

                  // log and deal with ExceptionTwo

            } catch (ExceptionThree e) {

                  // log and deal with ExceptionThree

            }

      }
      

Catching an endless number of exceptions one after the other in a catch block looks cluttered. And I have seen code that catches a dozen exceptions, too. This is incredibly inefficient and error prone. Java 7 has brought in a new language change to address this ugly duckling. See the improved version of the method oldMultiCatch method below:

      public void newMultiCatch() {

            try {

                  methodThatThrowsThreeExceptions();

            } catch (ExceptionOne | ExceptionTwo | ExceptionThree e) {

                  // log and deal with all Exceptions

            }

      }

The multiple exceptions are caught in one catch block by using a ‘|’ operator. This way, you do not have to write dozens of exception catches. However, if you have bunch of exceptions that belong to different types, then you could use “multi multi-catch” blocks too. The following snippet illustrates this:

public void newMultiMultiCatch() {

            try {

                  methodThatThrowsThreeExceptions();

            } catch (ExceptionOne e) {

                  // log and deal with ExceptionOne



            } catch (ExceptionTwo | ExceptionThree e) {

                  // log and deal with ExceptionTwo and ExceptionThree

            }



      }

In the above case, the ExceptionTwo and ExceptionThree belong to a different hierarchy, so you would want to handle them differently but with a single catch block.
New file system API (NIO 2.0)
Those who worked with Java IO may still remember the headaches that framework caused. It was never easy to work seamlessly across operating systems or multi-file systems. There were methods such as delete or rename that behaved unexpected in most cases. Working with symbolic links was another issue. In an essence, the API needed an overhaul.
With the intention of solving the above problems with Java IO, Java 7 introduced an overhauled and in many cases new API.
The NIO 2.0 has come forward with many enhancements. It’s also introduced new classes to ease the life of a developer when working with multiple file systems.
Working with Path
A new java.nio.file package consists of classes and interfaces such as Path, Paths,FileSystem, FileSystems and others.
A Path is simply a reference to a file path. It is the equivalent (and with more features) tojava.io.File. The following snippet shows how to obtain a path reference to the “temp” folder:

public void pathInfo() {

            Path path = Paths.get("c:\Temp\temp");

System.out.println("Number of Nodes:" + path.getNameCount());

            System.out.println("File Name:" + path.getFileName());

            System.out.println("File Root:" + path.getRoot());

            System.out.println("File Parent:" + path.getParent());

      }

The console output would be:

Number of Nodes:2

File Name:temp.txt

File Root:c:

File Parent:c:Temp

Deleting a file or directory is as simple as invoking a delete method on Files (note the plural) class. The Files class exposes two delete methods, one that throws NoSuchFileException and the other that does not.
The following delete method invocation throws NoSuchFileException, so you have to handle it:

Files.delete(path);

Where as Files.deleteIfExists(path) does not throw exception (as expected) if the file/directory does not exist.
You can use other utility methods such as Files.copy(..) and Files.move(..) to act on a file system efficiently. Similarly, use the createSymbolicLink(..) method to create symbolic links using your code.
File change notifications
One of my favorite improvements in the JDK 7 release is the addition of File Change Notifications. This has been a long-awaited feature that’s finally carved into NIO 2.0. TheWatchService API lets you receive notification events upon changes to the subject (directory or file).
The steps involved in implementing the API are:

    Create a WatchService. This service consists of a queue to hold WatchKeys
    Register the directory/file you wish to monitor with this WatchService
    While registering, specify the types of events you wish to receive (create, modify or delete events)
    You have to start an infinite loop to listen to events
    When an event occurs, a WatchKey is placed into the queue
    Consume the WatchKey and invoke queries on it

Let’s follow this via an example. We create a DirPolice Java program whose responsibility is to police a particular directory. The steps are provided below:
1. Creating a WatchService object:

WatchService  watchService = FileSystems.getDefault().newWatchService();

2. Obtain a path reference to your watchable directory. I suggest you parameterize this directory so you don’t hard code the file name.

path = Paths.get("C:\Temp\temp\");

3. The next step is to register the directory with the WatchService for all types of events:

dirToWatch.register(watchService, ENTRY_CREATE, ENTRY_MODIFY,

ENTRY_DELETE);

These are java.nio.file.StandardWatchEventKinds event types
4. Initiate the infinite loop and start taking the events:

while(true)

{

    WatchKey key = watchService.take(); // this would return you keys

    …

}

5. Run through the events on the key:

for (WatchEvent<?> event : key.pollEvents()) {

            Kind<?> kind = event.kind();

System.out.println("Event on " + event.context().toString() + " is " + kind);

}

For example, if you modify or delete the temp directory, you would see statement as shown below on the console respectively:

Event on temp is ENTRY_MODIFY

Event on temp is ENTRY_DELETE

The relevant methods of the DirPolice source code are posted below (download the full source code):

/**

 * This initiates the police

 */

private void init() {

      path = Paths.get("C:\Temp\temp\");

      try {

            watchService = FileSystems.getDefault().newWatchService();

            path.register(watchService, ENTRY_CREATE, ENTRY_DELETE,

                        ENTRY_MODIFY);

      } catch (IOException e) {

            System.out.println("IOException"+ e.getMessage());

      }

}

/**

 * The police will start making rounds

 */

private void doRounds() {

      WatchKey key = null;

      while(true) {

            try {

                  key = watchService.take();

                  for (WatchEvent<?> event : key.pollEvents()) {

                        Kind<?> kind = event.kind();

System.out.println("Event on " + event.context().toString() + " is " + kind);

                  }

            } catch (InterruptedException e) {

System.out.println("InterruptedException: "+e.getMessage());

            }

            boolean reset = key.reset();

            if(!reset)

                  break;

      }

}

Fork and Join
The effective use of parallel cores in a Java program has always been a challenge. There were few home-grown frameworks that would distribute the work across multiple cores and then join them to return the result set. Java 7 has incorporated this feature as a Fork and Join framework.
Basically the Fork-Join breaks the task at hand into mini-tasks until the mini-task is simple enough that it can be solved without further breakups. It’s like a divide-and-conquer algorithm. One important concept to note in this framework is that ideally no worker thread is idle. They implement a work-stealing algorithm in that idle workers “steal” the work from those workers who are busy.
The core classes supporting the Fork-Join mechanism are ForkJoinPool and ForkJoinTask. TheForkJoinPool is basically a specialized implementation of ExecutorService implementing thework-stealing algorithm we talked about above.
We create an instance of ForkJoinPool by providing the target parallelism level — the number of processors as shown below:

ForkJoinPool pool = new ForkJoinPool(numberOfProcessors)

Where numberOfProcessors = Runtime.getRunTime().availableProcessors();
However, the default ForkJoinPool instantiation would set the parallelism level equal to the same number obtained as above.
The problem that needs to be solved is coded in a ForkJoinTask. However, there are two implementations of this class out of the box: the RecursiveAction and RecursiveTask. The only difference between these two classes is that the former one does not return a value while the latter returns an object of specified type.
Here’s how to create a RecursiveAction or RecursiveTask class that represents your requirement problem (I use the RecursiveAction class):

public class MyBigProblemTask extends RecursiveAction {



    @Override

    protected void compute() {

        . . . // your problem invocation goes here

    }

}

You have to override the compute method where in you need to provide the computing functionality. Now, provide this ForkJoinTask to the Executor by calling invoke method on theForkJoinPool:

pool.invoke(task);

Supporting dynamism
Java is a statically typed language — the type checking of the variables, methods and return values is performed at compile time. The JVM executes this strongly-typed bytecode at runtime without having to worry about finding the type information.
There’s another breed of typed languages — the dynamically typed languages. Ruby, Python and Clojure are in this category. The type information is unresolved until runtime in these languages. This is not possible in Java as it would not have any necessary type information.
There is an increasing pressure on Java folks improvise running the dynamic languages efficiently. Although it is possible to run these languages on a JVM (using Reflection), it’s not without constraints and restrictions.
In Java 7, a new feature called invokedynamic was introduced. This makes VM changes to incorporate non-Java language requirements. A new package, java.lang.invoke, consisting of classes such as MethodHandle, CallSite and others, has been created to extend the support of dynamic languages.


</pre>
<hr style="border-top: 1px;" />
<pre>

<a name="javalangOutOfMemoryError" href="#/javaBlog#javalangOutOfMemoryError" >What is java.lang.OutOfMemoryError in Java ?</a>

 

OutOfMemoryError in Java is a subclass of java.lang.VirtualMachineError and JVM throws java.lang.OutOfMemoryError when it ran out of memory in the heap. OutOfMemoryError in Java can come anytime in heap mostly while you try to create an object and there is not enough space on the heap to allocate that object. Javadoc of OutOfMemoryError is not very informative about this, though.

I have seen mainly two types of OutOfMemoryError in Java:

1) The java.lang.OutOfMemoryError: Java heap space
2) The java.lang.OutOfMemoryError: PermGen space

Though both of them occur because JVM ran out of memory they are quite different to each other and their solutions are independent of each other.


Since in most of JVM default size of Perm Space is around "64MB" you can easily run out of memory if you have too many classes or a huge number of Strings in your project.

How to solve java.lang.OutOfMemoryError: Java heap space

1) An easy way to solve OutOfMemoryError in java is to increase the maximum heap size by using JVM options "-Xmx512M", this will immediately solve your OutOfMemoryError. This is my preferred solution when I get OutOfMemoryError in Eclipse, Maven or ANT while building project because based upon size of project you can easily run out of Memory.here is an example of increasing maximum heap size of JVM, Also its better to keep -Xmx to -Xms ration either 1:1 or 1:1.5 if you are setting heap size in your java application

export JVM_ARGS="-Xms1024m -Xmx1024m"

2) The second way to resolve OutOfMemoryError in Java is rather hard and  comes when you don't have much memory and even after increase maximum heap size you are still getting java.lang.OutOfMemoryError, in this case, you probably want to profile your application and look for any memory leak. You can use Eclipse Memory Analyzer to examine your heap dump or you can use any profiler like Netbeans or JProbe. This is tough solution and requires some time to analyze and find memory leaks.

How to solve java.lang.OutOfMemoryError: PermGen space
As explained in above paragraph this OutOfMemory error in java comes when Permanent generation of heap filled up. To fix this OutOfMemoryError in Java, you need to increase heap size of Perm space by using JVM option   "-XX: MaxPermSize". You can also specify initial size of Perm space by using    "-XX: PermSize" and keeping both initial and maximum Perm Space you can prevent some full garbage collection which may occur when Perm Space gets re-sized. Here is how you can specify initial and maximum Perm size in Java:

export JVM_ARGS="-XX:PermSize=64M -XX:MaxPermSize=256m"

Some time java.lang.OutOfMemoryError  in Java gets tricky and on those cases profiling remains ultimate solution.Though you have the freedom to increase heap size in java, it’s recommended that to follow memory management practices while coding and setting null to any unused references.

</pre>

<hr style="border-top: 1px;" />


SOLID Principle help you to not write frigile, regid and unresuable code

S	SRP		Single responsibility principle
			a class should have only a single responsibility (i.e. only one potential change in the software's specification should be able to affect the specification of the class)
			
O	OCP		Open/closed principle
			“software entities … should be open for extension, but closed for modification.”

L	LSP		Liskov substitution principle
			“objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program.” See also design by contract.
			
I	ISP		Interface segregation principle
			“many client-specific interfaces are better than one general-purpose interface.”
			
D	DIP	 	Dependency inversion principle one should “depend upon abstractions, [not] concretions.”


<pre>

